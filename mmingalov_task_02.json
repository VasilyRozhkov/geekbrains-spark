{"paragraphs":[{"title":"Как выполнять","text":"%md\n.\n.\n.\nНужно скопировать себе эту тетрадку и предоставить доступ к копии на чтение, запись и запуск тетрадки пользователю admin. Параграфы с генерацией данных и созданием семплов запускать не нужно, они оставлены для ознакомления","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T06:44:39+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>.\n<br  />.\n<br  />.\n<br  />Нужно скопировать себе эту тетрадку и предоставить доступ к копии на чтение, запись и запуск тетрадки пользователю admin. Параграфы с генерацией данных и созданием семплов запускать не нужно, они оставлены для ознакомления</p>\n"}]},"apps":[],"jobName":"paragraph_1606773354942_-398453033","id":"20201127-213054_1829929461","dateCreated":"2020-11-30T21:55:54+0000","dateStarted":"2020-12-01T06:44:39+0000","dateFinished":"2020-12-01T06:44:39+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:14522"},{"title":"Генерация events таблицы","text":"import org.apache.spark.mllib.random.RandomRDDs._\nimport java.time.LocalDate\nimport java.time.format.DateTimeFormatter\n\nval dates = (0 to 14).map(LocalDate.of(2020, 11, 1).plusDays(_).format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd\"))).toSeq\n\ndef generateCity(r: Double): String = if (r < 0.9) \"BIG_CITY\" else \"SMALL_CITY_\" + scala.math.round((r - 0.9) * 1000)\n\ndef generateCityUdf = udf(generateCity _)\n\n// spark.sql(\"drop table hw2.events_full\")\n\nfor(i <- dates) {\n    uniformRDD(sc, 10000000L, 1)\n    .toDF(\"uid\")\n    .withColumn(\"date\", lit(i))\n    .withColumn(\"city\", generateCityUdf($\"uid\"))\n    .selectExpr(\"date\", \" sha2(cast(uid as STRING), 256) event_id\", \"city\")\n    .withColumn(\"skew_key\", when($\"city\" === \"BIG_CITY\", lit(\"big_event\")).otherwise($\"event_id\"))\n    .write.mode(\"append\")\n    .partitionBy(\"date\")\n    .saveAsTable(\"hw2.events_full\")\n}\n","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T01:57:04+0000","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":false,"editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.mllib.random.RandomRDDs._\nimport java.time.LocalDate\nimport java.time.format.DateTimeFormatter\ndates: scala.collection.immutable.Seq[String] = Vector(2020-11-01, 2020-11-02, 2020-11-03, 2020-11-04, 2020-11-05, 2020-11-06, 2020-11-07, 2020-11-08, 2020-11-09, 2020-11-10, 2020-11-11, 2020-11-12, 2020-11-13, 2020-11-14, 2020-11-15)\ngenerateCity: (r: Double)String\ngenerateCityUdf: org.apache.spark.sql.expressions.UserDefinedFunction\n"}]},"apps":[],"jobName":"paragraph_1606773354944_-361164742","id":"20201127-224038_803369215","dateCreated":"2020-11-30T21:55:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:14523"},{"title":"Генерация events_sample","text":"spark.table(\"hw2.events_full\")\n.select(\"event_id\")\n.sample(0.0005)\n.repartition(2)\n.write.mode(\"overwrite\")\n.saveAsTable(\"hw2.sample\")\n","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T02:07:03+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":3,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1606773354944_-722985956","id":"20201127-230139_1962818180","dateCreated":"2020-11-30T21:55:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:14524"},{"text":"\nspark.table(\"hw2.sample\")\n.limit(100)\n.coalesce(1)\n.write.mode(\"overwrite\")\n.saveAsTable(\"hw2.sample_small\")","user":"BD_274_mmingalov","dateUpdated":"2020-11-30T21:55:54+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":3,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1606773354944_-1000872767","id":"20201128-000812_530567540","dateCreated":"2020-11-30T21:55:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:14525"},{"text":"\n\nspark.table(\"hw2.events_full\")\n.select(\"event_id\")\n.sample(0.003)\n.repartition(1)\n.write.mode(\"overwrite\")\n.saveAsTable(\"hw2.sample_big\")","user":"BD_274_mmingalov","dateUpdated":"2020-11-30T21:55:54+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":3,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1606773354945_278877530","id":"20201128-091248_492627774","dateCreated":"2020-11-30T21:55:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:14526"},{"text":"\n\nspark.table(\"hw2.events_full\")\n.select(\"event_id\")\n.sample(0.015)\n.repartition(1)\n.write.mode(\"overwrite\")\n.saveAsTable(\"hw2.sample_very_big\")","user":"BD_274_mmingalov","dateUpdated":"2020-11-30T21:55:54+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":3,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1606773354945_1239587518","id":"20201128-093907_1614062530","dateCreated":"2020-11-30T21:55:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:14527"},{"title":"Задание 1","text":"%md\n\nДля упражнений сгрененирован большой набор синтетических данных в таблице hw2.events_full. Из этого набора данных созданы маленькие (относительно исходного набора) таблицы разного размера kotelnikov.sample_[small, big, very_big]. \n\nОтветить на вопросы:\n * какова структура таблиц\n * сколько в них записей \n * сколько места занимают данные\n\n\n","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T06:44:48+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{"0":{"graph":{"mode":"table","height":163.368,"optionOpen":false}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Для упражнений сгрененирован большой набор синтетических данных в таблице hw2.events_full. Из этого набора данных созданы маленькие (относительно исходного набора) таблицы разного размера kotelnikov.sample_[small, big, very_big].</p>\n<p>Ответить на вопросы:</p>\n<ul>\n<li>какова структура таблиц</li>\n<li>сколько в них записей</li>\n<li>сколько места занимают данные</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1606773354946_2121216235","id":"20201128-094640_2955666","dateCreated":"2020-11-30T21:55:54+0000","dateStarted":"2020-12-01T06:44:48+0000","dateFinished":"2020-12-01T06:44:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14528"},{"text":"%pyspark\nspark.table(\"hw2.events_full\").show()\nspark.table(\"hw2.sample\").show()\nspark.table(\"hw2.sample_small\").show()\nspark.table(\"hw2.sample_big\").show()\nspark.table(\"hw2.sample_very_big\").show()","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T06:59:18+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+-------------+--------------------+----------+\n|            event_id|         city|            skew_key|      date|\n+--------------------+-------------+--------------------+----------+\n|ebb49beaa3480a925...|     BIG_CITY|           big_event|2020-11-01|\n|201dd7d3633c307de...|SMALL_CITY_28|201dd7d3633c307de...|2020-11-01|\n|cd5d3a8cde83024ba...|     BIG_CITY|           big_event|2020-11-01|\n|24c5603bc2f67ae6a...|     BIG_CITY|           big_event|2020-11-01|\n|456cd75a534951cdb...|     BIG_CITY|           big_event|2020-11-01|\n|a2a8f38ad203620fc...|     BIG_CITY|           big_event|2020-11-01|\n|c0ab112dd0c51b48d...|SMALL_CITY_42|c0ab112dd0c51b48d...|2020-11-01|\n|066842683c29c3f1f...|     BIG_CITY|           big_event|2020-11-01|\n|cdd1a0fecfb0fb4c3...|     BIG_CITY|           big_event|2020-11-01|\n|86e5eb86107c76e3a...|     BIG_CITY|           big_event|2020-11-01|\n|117fdbbb8b622155b...|     BIG_CITY|           big_event|2020-11-01|\n|8fc9f2527b0d6e780...|SMALL_CITY_42|8fc9f2527b0d6e780...|2020-11-01|\n|2e96a18c96b318e0e...|     BIG_CITY|           big_event|2020-11-01|\n|cc94217d53a0c434a...|     BIG_CITY|           big_event|2020-11-01|\n|89f6e3373170573b1...|     BIG_CITY|           big_event|2020-11-01|\n|62e66ac9f9d2da88a...|     BIG_CITY|           big_event|2020-11-01|\n|4da4bb0e4bb62a83f...|     BIG_CITY|           big_event|2020-11-01|\n|8e1af81f00c2a46d2...|     BIG_CITY|           big_event|2020-11-01|\n|e1771c9480b596c39...|     BIG_CITY|           big_event|2020-11-01|\n|1859b0f2ee9c5ad44...|     BIG_CITY|           big_event|2020-11-01|\n+--------------------+-------------+--------------------+----------+\nonly showing top 20 rows\n\n+--------------------+\n|            event_id|\n+--------------------+\n|a368a3975fb2026f4...|\n|e78391cb5f7041754...|\n|76c024c74fe086939...|\n|e871ca8c1356fbbbe...|\n|ff2bd51eda11f0469...|\n|ea7d0f3432aa5a455...|\n|2e4b79cebf8c8ba26...|\n|486008d0bdb800325...|\n|150dec7081370a545...|\n|6c941ea697a6ffa7a...|\n|16dde2278f2034dbf...|\n|d8792192085ad24c5...|\n|4d3c0c80378f38bda...|\n|def11ed515926b0bf...|\n|661b3a92306c0d6a2...|\n|3f3f670bd39a89cc4...|\n|d20f62eff592ea140...|\n|d48c89eb8e64fb019...|\n|a4c1d6ecc66c9677b...|\n|d6b01aaf5adb4586c...|\n+--------------------+\nonly showing top 20 rows\n\n+--------------------+\n|            event_id|\n+--------------------+\n|a368a3975fb2026f4...|\n|e78391cb5f7041754...|\n|76c024c74fe086939...|\n|e871ca8c1356fbbbe...|\n|ff2bd51eda11f0469...|\n|ea7d0f3432aa5a455...|\n|2e4b79cebf8c8ba26...|\n|486008d0bdb800325...|\n|150dec7081370a545...|\n|6c941ea697a6ffa7a...|\n|16dde2278f2034dbf...|\n|d8792192085ad24c5...|\n|4d3c0c80378f38bda...|\n|def11ed515926b0bf...|\n|661b3a92306c0d6a2...|\n|3f3f670bd39a89cc4...|\n|d20f62eff592ea140...|\n|d48c89eb8e64fb019...|\n|a4c1d6ecc66c9677b...|\n|d6b01aaf5adb4586c...|\n+--------------------+\nonly showing top 20 rows\n\n+--------------------+\n|            event_id|\n+--------------------+\n|d5c636589be142ef5...|\n|771811eb5c077910c...|\n|16dc57015780bab62...|\n|db26d54dbe6174e6c...|\n|824e74ce26ce613c2...|\n|4bbcb78c15659f5b8...|\n|68032039730513104...|\n|50e9148a847d9ecdb...|\n|ba872aa567036e772...|\n|64a154a8fba2cf403...|\n|d18fc4e2325ad4dc2...|\n|97661828d98f4e582...|\n|9fd5f320d40fbc767...|\n|2bc7742b98e71dae9...|\n|753469762b67b61e7...|\n|4f283d4ba45a4515c...|\n|e3e5dc2e06fed8e3a...|\n|0903263909c685539...|\n|443dca99b2cdee77e...|\n|3eb50185daddde4b9...|\n+--------------------+\nonly showing top 20 rows\n\n+--------------------+\n|            event_id|\n+--------------------+\n|4da4bb0e4bb62a83f...|\n|c2f513e81c4257e68...|\n|f729fb12f3c864d35...|\n|5b240d1ef1d6cceef...|\n|57c5c19c8887ecd7a...|\n|65eb92cd3c4bc1888...|\n|5d796c0686372927e...|\n|106f633e28acd7a3d...|\n|c4eaee6a6e9653f0e...|\n|1632d12a817f6ff95...|\n|b2b60ad6b86c5cb2b...|\n|88aba95585ca29252...|\n|0b30ddba2779daf66...|\n|db1ac54a5944d2d08...|\n|3b105df06b1395ac6...|\n|0eaeff60098f32904...|\n|c48dea068959c7eed...|\n|046042e486d01b36e...|\n|4b944d2d492ce0060...|\n|05c003cdcef86290f...|\n+--------------------+\nonly showing top 20 rows\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://bigdataanalytics-head-0.novalocal:4040/jobs/job?id=0","http://bigdataanalytics-head-0.novalocal:4040/jobs/job?id=1","http://bigdataanalytics-head-0.novalocal:4040/jobs/job?id=2","http://bigdataanalytics-head-0.novalocal:4040/jobs/job?id=3","http://bigdataanalytics-head-0.novalocal:4040/jobs/job?id=4"],"interpreterSettingId":"spark2"}},"apps":[],"jobName":"paragraph_1606788081453_1966024359","id":"20201201-020121_815728103","dateCreated":"2020-12-01T02:01:21+0000","dateStarted":"2020-12-01T06:59:18+0000","dateFinished":"2020-12-01T06:59:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14529"},{"title":"структура таблиц","text":"%pyspark\nspark.table(\"hw2.events_full\").printSchema()\nspark.table(\"hw2.sample\").printSchema()\nspark.table(\"hw2.sample_small\").printSchema()\nspark.table(\"hw2.sample_big\").printSchema()\nspark.table(\"hw2.sample_very_big\").printSchema()","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T07:00:04+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- event_id: string (nullable = true)\n |-- city: string (nullable = true)\n |-- skew_key: string (nullable = true)\n |-- date: string (nullable = true)\n\nroot\n |-- event_id: string (nullable = true)\n\nroot\n |-- event_id: string (nullable = true)\n\nroot\n |-- event_id: string (nullable = true)\n\nroot\n |-- event_id: string (nullable = true)\n\n"}]},"apps":[],"jobName":"paragraph_1606790279090_1958603130","id":"20201201-023759_2077436343","dateCreated":"2020-12-01T02:37:59+0000","dateStarted":"2020-12-01T07:00:05+0000","dateFinished":"2020-12-01T07:00:05+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14530"},{"title":"объем данные в sample, sample_small, sample_big, sample_very_big","text":"%pyspark\nprint(spark.table(\"hw2.sample\").count(), spark.table(\"hw2.sample_small\").count(), spark.table(\"hw2.sample_big\").count(), spark.table(\"hw2.sample_very_big\").count())","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T07:00:19+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"(74650, 100, 449166, 2248079)\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://bigdataanalytics-head-0.novalocal:4040/jobs/job?id=5","http://bigdataanalytics-head-0.novalocal:4040/jobs/job?id=6","http://bigdataanalytics-head-0.novalocal:4040/jobs/job?id=7","http://bigdataanalytics-head-0.novalocal:4040/jobs/job?id=8"],"interpreterSettingId":"spark2"}},"apps":[],"jobName":"paragraph_1606788566429_-523572564","id":"20201201-020926_1639322595","dateCreated":"2020-12-01T02:09:26+0000","dateStarted":"2020-12-01T07:00:19+0000","dateFinished":"2020-12-01T07:00:21+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14531"},{"title":"сколько места занимают данные sample","text":"%sh\nhdfs dfs -ls /apps/spark/warehouse/hw2.db/sample\nhdfs dfs -ls /apps/spark/warehouse/hw2.db/sample_big\nhdfs dfs -ls /apps/spark/warehouse/hw2.db/sample_small\nhdfs dfs -ls /apps/spark/warehouse/hw2.db/sample_very_big\n\n","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T07:00:24+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/sh","editorHide":false,"tableHide":false,"title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Found 3 items\n-rw-r--r--   3 zeppelin hdfs          0 2020-11-28 13:47 /apps/spark/warehouse/hw2.db/sample/_SUCCESS\n-rw-r--r--   3 zeppelin hdfs    2379515 2020-11-28 13:47 /apps/spark/warehouse/hw2.db/sample/part-00000-9c420194-6d4f-4f1d-9ab0-59b5f03b685f-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs    2376942 2020-11-28 13:47 /apps/spark/warehouse/hw2.db/sample/part-00001-9c420194-6d4f-4f1d-9ab0-59b5f03b685f-c000.snappy.parquet\nFound 2 items\n-rw-r--r--   3 zeppelin hdfs          0 2020-11-28 13:59 /apps/spark/warehouse/hw2.db/sample_big/_SUCCESS\n-rw-r--r--   3 zeppelin hdfs   28608600 2020-11-28 13:59 /apps/spark/warehouse/hw2.db/sample_big/part-00000-2e675e67-3869-4e4e-85aa-201aa97bdc7f-c000.snappy.parquet\nFound 2 items\n-rw-r--r--   3 zeppelin hdfs          0 2020-11-28 13:49 /apps/spark/warehouse/hw2.db/sample_small/_SUCCESS\n-rw-r--r--   3 zeppelin hdfs       7224 2020-11-28 13:49 /apps/spark/warehouse/hw2.db/sample_small/part-00000-e9dbd1a4-aacb-4807-841a-e23995863b00-c000.snappy.parquet\nFound 2 items\n-rw-r--r--   3 zeppelin hdfs          0 2020-11-28 13:58 /apps/spark/warehouse/hw2.db/sample_very_big/_SUCCESS\n-rw-r--r--   3 zeppelin hdfs  143186369 2020-11-28 13:58 /apps/spark/warehouse/hw2.db/sample_very_big/part-00000-3d3f8f75-8478-4860-85e8-55771c746139-c000.snappy.parquet\n"}]},"apps":[],"jobName":"paragraph_1606788430034_1755286365","id":"20201201-020710_1835764034","dateCreated":"2020-12-01T02:07:10+0000","dateStarted":"2020-12-01T07:00:25+0000","dateFinished":"2020-12-01T07:00:35+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14532"},{"title":"Задание 2","text":"%md\n\nПолучить планы запросов для джойна большой таблицы hw2.events_full с каждой из таблиц hw2.sample, hw2.sample_big, hw2.sample_very_big по полю event_id. В каких случаях используется BroadcastHashJoin? \n\nBroadcastHashJoin автоматически выполняется для джойна с таблицами, размером меньше параметра spark.sql.autoBroadcastJoinThreshold. Узнать его значение можно командой spark.conf.get(\"spark.sql.autoBroadcastJoinThreshold\").","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T07:00:42+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Получить планы запросов для джойна большой таблицы hw2.events_full с каждой из таблиц hw2.sample, hw2.sample_big, hw2.sample_very_big по полю event_id. В каких случаях используется BroadcastHashJoin?</p>\n<p>BroadcastHashJoin автоматически выполняется для джойна с таблицами, размером меньше параметра spark.sql.autoBroadcastJoinThreshold. Узнать его значение можно командой spark.conf.get(&ldquo;spark.sql.autoBroadcastJoinThreshold&rdquo;).</p>\n"}]},"apps":[],"jobName":"paragraph_1606773354946_848664853","id":"20201128-132950_831220047","dateCreated":"2020-11-30T21:55:54+0000","dateStarted":"2020-12-01T07:00:42+0000","dateFinished":"2020-12-01T07:00:45+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14533"},{"title":"BroadcastHashJoin is using here","text":"spark.sql(\"\"\"\nselect count(*) from hw2.events_full\ninner join hw2.sample on events_full.event_id = sample.event_id\n\"\"\").explain","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T07:00:48+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"== Physical Plan ==\n*(3) HashAggregate(keys=[], functions=[count(1)])\n+- Exchange SinglePartition\n   +- *(2) HashAggregate(keys=[], functions=[partial_count(1)])\n      +- *(2) Project\n         +- *(2) BroadcastHashJoin [event_id#0], [event_id#22], Inner, BuildRight\n            :- *(2) Project [event_id#0]\n            :  +- *(2) Filter isnotnull(event_id#0)\n            :     +- *(2) FileScan parquet hw2.events_full[event_id#0,date#3] Batched: true, Format: Parquet, Location: CatalogFileIndex[hdfs://bigdataanalytics-head-0.novalocal:8020/apps/spark/warehouse/hw2.db/events..., PartitionCount: 15, PartitionFilters: [], PushedFilters: [IsNotNull(event_id)], ReadSchema: struct<event_id:string>\n            +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]))\n               +- *(1) Project [event_id#22]\n                  +- *(1) Filter isnotnull(event_id#22)\n                     +- *(1) FileScan parquet hw2.sample[event_id#22] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://bigdataanalytics-head-0.novalocal:8020/apps/spark/warehouse/hw2.db/sample], PartitionFilters: [], PushedFilters: [IsNotNull(event_id)], ReadSchema: struct<event_id:string>\n"}]},"apps":[],"jobName":"paragraph_1606789083867_1754033129","id":"20201201-021803_311848166","dateCreated":"2020-12-01T02:18:03+0000","dateStarted":"2020-12-01T07:00:49+0000","dateFinished":"2020-12-01T07:00:49+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14534"},{"text":"spark.sql(\"\"\"\nselect count(*) from hw2.events_full\ninner join hw2.sample_big on events_full.event_id = sample_big.event_id\n\"\"\").explain","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T02:20:26+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"== Physical Plan ==\n*(6) HashAggregate(keys=[], functions=[count(1)])\n+- Exchange SinglePartition\n   +- *(5) HashAggregate(keys=[], functions=[partial_count(1)])\n      +- *(5) Project\n         +- *(5) SortMergeJoin [event_id#59], [event_id#42], Inner\n            :- *(2) Sort [event_id#59 ASC NULLS FIRST], false, 0\n            :  +- Exchange hashpartitioning(event_id#59, 200)\n            :     +- *(1) Project [event_id#59]\n            :        +- *(1) Filter isnotnull(event_id#59)\n            :           +- *(1) FileScan parquet hw2.events_full[event_id#59,date#62] Batched: true, Format: Parquet, Location: CatalogFileIndex[hdfs://bigdataanalytics-head-0.novalocal:8020/apps/spark/warehouse/hw2.db/events..., PartitionCount: 15, PartitionFilters: [], PushedFilters: [IsNotNull(event_id)], ReadSchema: struct<event_id:string>\n            +- *(4) Sort [event_id#42 ASC NULLS FIRST], false, 0\n               +- Exchange hashpartitioning(event_id#42, 200)\n                  +- *(3) Project [event_id#42]\n                     +- *(3) Filter isnotnull(event_id#42)\n                        +- *(3) FileScan parquet hw2.sample_big[event_id#42] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://bigdataanalytics-head-0.novalocal:8020/apps/spark/warehouse/hw2.db/sampl..., PartitionFilters: [], PushedFilters: [IsNotNull(event_id)], ReadSchema: struct<event_id:string>\n"}]},"apps":[],"jobName":"paragraph_1606789198789_326359132","id":"20201201-021958_1162275482","dateCreated":"2020-12-01T02:19:58+0000","dateStarted":"2020-12-01T02:20:26+0000","dateFinished":"2020-12-01T02:20:26+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14535"},{"text":"spark.sql(\"\"\"\nselect count(*) from hw2.events_full\ninner join hw2.sample_very_big on events_full.event_id = sample_very_big.event_id\n\"\"\").explain","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T02:20:47+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"== Physical Plan ==\n*(6) HashAggregate(keys=[], functions=[count(1)])\n+- Exchange SinglePartition\n   +- *(5) HashAggregate(keys=[], functions=[partial_count(1)])\n      +- *(5) Project\n         +- *(5) SortMergeJoin [event_id#59], [event_id#50], Inner\n            :- *(2) Sort [event_id#59 ASC NULLS FIRST], false, 0\n            :  +- Exchange hashpartitioning(event_id#59, 200)\n            :     +- *(1) Project [event_id#59]\n            :        +- *(1) Filter isnotnull(event_id#59)\n            :           +- *(1) FileScan parquet hw2.events_full[event_id#59,date#62] Batched: true, Format: Parquet, Location: CatalogFileIndex[hdfs://bigdataanalytics-head-0.novalocal:8020/apps/spark/warehouse/hw2.db/events..., PartitionCount: 15, PartitionFilters: [], PushedFilters: [IsNotNull(event_id)], ReadSchema: struct<event_id:string>\n            +- *(4) Sort [event_id#50 ASC NULLS FIRST], false, 0\n               +- Exchange hashpartitioning(event_id#50, 200)\n                  +- *(3) Project [event_id#50]\n                     +- *(3) Filter isnotnull(event_id#50)\n                        +- *(3) FileScan parquet hw2.sample_very_big[event_id#50] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://bigdataanalytics-head-0.novalocal:8020/apps/spark/warehouse/hw2.db/sampl..., PartitionFilters: [], PushedFilters: [IsNotNull(event_id)], ReadSchema: struct<event_id:string>\n"}]},"apps":[],"jobName":"paragraph_1606789229411_1129054268","id":"20201201-022029_1924133824","dateCreated":"2020-12-01T02:20:29+0000","dateStarted":"2020-12-01T02:20:47+0000","dateFinished":"2020-12-01T02:20:47+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14536"},{"title":"Задание 3","text":"%md\n.\n.\n.\n\nВыполнить джойны с таблицами  hw2.sample,  hw2.sample_big в отдельных параграфах, чтобы узнать время выполнения запросов (например, вызвать .count() для результатов запросов). Время выполнения параграфа считается автоматически и указывается в нижней части по завершении\n\nЗайти в spark ui (ссылку сгенерировать в следующем папраграфе). Сколько tasks создано на каждую операцию? Почему именно столько? Каков DAG вычислений?  ","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T02:01:16+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{"0":{"graph":{"mode":"table","height":134.159,"optionOpen":false}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>.\n<br  />.\n<br  />.</p>\n<p>Выполнить джойны с таблицами  hw2.sample,  hw2.sample_big в отдельных параграфах, чтобы узнать время выполнения запросов (например, вызвать .count() для результатов запросов). Время выполнения параграфа считается автоматически и указывается в нижней части по завершении</p>\n<p>Зайти в spark ui (ссылку сгенерировать в следующем папраграфе). Сколько tasks создано на каждую операцию? Почему именно столько? Каков DAG вычислений?</p>\n"}]},"apps":[],"jobName":"paragraph_1606773354947_-1924196471","id":"20201128-140231_1065047171","dateCreated":"2020-11-30T21:55:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:14537"},{"title":"join sample via SQL way","text":"spark.sql(\"\"\"\nselect count(*) from hw2.events_full\ninner join hw2.sample on events_full.event_id = sample.event_id\n\"\"\").show()","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T04:18:56+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------+\n|count(1)|\n+--------+\n|   74650|\n+--------+\n\n"}]},"apps":[],"jobName":"paragraph_1606789379003_256966368","id":"20201201-022259_279607607","dateCreated":"2020-12-01T02:22:59+0000","dateStarted":"2020-12-01T04:18:56+0000","dateFinished":"2020-12-01T04:19:47+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14538"},{"title":"join sample_big via SQL way","text":"spark.sql(\"\"\"\nselect count(*) from hw2.events_full\ninner join hw2.sample_big on events_full.event_id = sample_big.event_id\n\"\"\").show()","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T04:33:38+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------+\n|count(1)|\n+--------+\n|  449166|\n+--------+\n\n"}]},"apps":[],"jobName":"paragraph_1606789563924_1402813382","id":"20201201-022603_148519654","dateCreated":"2020-12-01T02:26:03+0000","dateStarted":"2020-12-01T04:33:38+0000","dateFinished":"2020-12-01T04:37:02+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14539"},{"title":"join sample via Spark API way","text":"spark.table(\"hw2.events_full\")\n.join(spark.table(\"hw2.sample\"),Seq(\"event_id\"))\n.count","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T06:18:36+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","title":true,"editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res8: Long = 74650\n"}]},"apps":[],"jobName":"paragraph_1606790946845_261162058","id":"20201201-024906_1589104171","dateCreated":"2020-12-01T02:49:06+0000","dateStarted":"2020-12-01T02:53:13+0000","dateFinished":"2020-12-01T02:54:04+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14540"},{"title":"join sample_big via Spark API way","text":"spark.table(\"hw2.events_full\")\n.join(spark.table(\"hw2.sample_big\"),Seq(\"event_id\"))\n.count","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T06:19:44+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","title":true,"editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res16: Long = 449166\n"}]},"apps":[],"jobName":"paragraph_1606803521281_501928190","id":"20201201-061841_1611435244","dateCreated":"2020-12-01T06:18:41+0000","dateStarted":"2020-12-01T06:19:44+0000","dateFinished":"2020-12-01T06:23:08+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14541"},{"title":"Генерация ссылки на  spark UI","text":"println(\"185.241.193.174:8088/proxy/\" + sc.applicationId + \"/jobs/\")\n","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T10:15:00+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"185.241.193.174:8088/proxy/application_1606749437001_0007/jobs/\n"}]},"apps":[],"jobName":"paragraph_1606773354947_827713335","id":"20201128-150602_756898802","dateCreated":"2020-11-30T21:55:54+0000","dateStarted":"2020-12-01T10:15:00+0000","dateFinished":"2020-12-01T10:15:01+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14542"},{"text":"%md\nМы видим, что на каждую операцию создано разное кол-во тасков 82 vs 284","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T06:04:30+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Мы видим, что на каждую операцию создано разное кол-во тасков 82 vs 284</p>\n"}]},"apps":[],"jobName":"paragraph_1606802390690_-2002649103","id":"20201201-055950_252950041","dateCreated":"2020-12-01T05:59:50+0000","dateStarted":"2020-12-01T06:04:30+0000","dateFinished":"2020-12-01T06:04:30+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14543"},{"title":"Посмотрим настройки параметра broadcast (в мегабайтах)","text":"spark.conf.get(\"spark.sql.autoBroadcastJoinThreshold\").toInt / 1024 / 1024\n","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T06:11:08+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res14: Int = 25\n"}]},"apps":[],"jobName":"paragraph_1606802785323_-673918340","id":"20201201-060625_1961491992","dateCreated":"2020-12-01T06:06:25+0000","dateStarted":"2020-12-01T06:11:08+0000","dateFinished":"2020-12-01T06:11:08+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14544"},{"text":"%md\nМы знаем, что наша таблица sample_big имеет размер 27 мегабайт -- нарочно чуть больше чем текущий параметр autoBroadcastJoinThreshold\nСоответственно, применяется не broadcast, а другой алгоритм","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T06:13:57+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Мы знаем, что наша таблица sample_big имеет размер 27 мегабайт &ndash; нарочно чуть больше чем текущий параметр autoBroadcastJoinThreshold\n<br  />Соответственно, применяется не broadcast, а другой алгоритм</p>\n"}]},"apps":[],"jobName":"paragraph_1606803128028_354476013","id":"20201201-061208_1932705176","dateCreated":"2020-12-01T06:12:08+0000","dateStarted":"2020-12-01T06:13:57+0000","dateFinished":"2020-12-01T06:13:57+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14545"},{"title":"Насильный broadcast","text":"%md\n\nОптимизировать джойн с таблицами hw2.sample_big, hw2.sample_very_big с помощью broadcast(df). Выполнить запрос, посмотреть в UI, как поменялся план запроса, DAG, количество тасков. Второй запрос не выполнится ","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T06:15:17+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Оптимизировать джойн с таблицами hw2.sample_big, hw2.sample_very_big с помощью broadcast(df). Выполнить запрос, посмотреть в UI, как поменялся план запроса, DAG, количество тасков. Второй запрос не выполнится</p>\n"}]},"apps":[],"jobName":"paragraph_1606773354948_-99632235","id":"20201128-140749_375295552","dateCreated":"2020-11-30T21:55:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:14546"},{"title":"time measurement: 58sec instead of 3min 24sec above","text":"spark.table(\"hw2.events_full\")\n.join(broadcast(spark.table(\"hw2.sample_big\")),Seq(\"event_id\"))\n.count","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T06:23:53+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res15: Long = 449166\n"}]},"apps":[],"jobName":"paragraph_1606803350345_8881594","id":"20201201-061550_2081720393","dateCreated":"2020-12-01T06:15:50+0000","dateStarted":"2020-12-01T06:17:59+0000","dateFinished":"2020-12-01T06:18:57+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14547"},{"title":"time measurement: error","text":"spark.table(\"hw2.events_full\")\n.join(broadcast(spark.table(\"hw2.sample_very_big\")),Seq(\"event_id\"))\n.count","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T06:33:13+0000","config":{"colWidth":12,"fontSize":9,"enabled":false,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"title":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:\nExchange SinglePartition\n+- *(2) HashAggregate(keys=[], functions=[partial_count(1)], output=[count#1417L])\n   +- *(2) Project\n      +- *(2) BroadcastHashJoin [event_id#59], [event_id#50], Inner, BuildRight\n         :- *(2) Project [event_id#59]\n         :  +- *(2) Filter isnotnull(event_id#59)\n         :     +- *(2) FileScan parquet hw2.events_full[event_id#59,date#62] Batched: true, Format: Parquet, Location: CatalogFileIndex[hdfs://bigdataanalytics-head-0.novalocal:8020/apps/spark/warehouse/hw2.db/events..., PartitionCount: 15, PartitionFilters: [], PushedFilters: [IsNotNull(event_id)], ReadSchema: struct<event_id:string>\n         +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]))\n            +- *(1) Project [event_id#50]\n               +- *(1) Filter isnotnull(event_id#50)\n                  +- *(1) FileScan parquet hw2.sample_very_big[event_id#50] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://bigdataanalytics-head-0.novalocal:8020/apps/spark/warehouse/hw2.db/sampl..., PartitionFilters: [], PushedFilters: [IsNotNull(event_id)], ReadSchema: struct<event_id:string>\n\n  at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:56)\n  at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n  at org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:371)\n  at org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:150)\n  at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:605)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n  at org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:247)\n  at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:294)\n  at org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2775)\n  at org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2774)\n  at org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3259)\n  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n  at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3258)\n  at org.apache.spark.sql.Dataset.count(Dataset.scala:2774)\n  ... 47 elided\nCaused by: java.util.concurrent.TimeoutException: Futures timed out after [300 seconds]\n  at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:223)\n  at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:227)\n  at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:201)\n  at org.apache.spark.sql.execution.exchange.BroadcastExchangeExec.doExecuteBroadcast(BroadcastExchangeExec.scala:136)\n  at org.apache.spark.sql.execution.InputAdapter.doExecuteBroadcast(WholeStageCodegenExec.scala:367)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeBroadcast$1.apply(SparkPlan.scala:144)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeBroadcast$1.apply(SparkPlan.scala:140)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n  at org.apache.spark.sql.execution.SparkPlan.executeBroadcast(SparkPlan.scala:140)\n  at org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.prepareBroadcast(BroadcastHashJoinExec.scala:135)\n  at org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.codegenInner(BroadcastHashJoinExec.scala:232)\n  at org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doConsume(BroadcastHashJoinExec.scala:102)\n  at org.apache.spark.sql.execution.CodegenSupport$class.constructDoConsumeFunction(WholeStageCodegenExec.scala:208)\n  at org.apache.spark.sql.execution.CodegenSupport$class.consume(WholeStageCodegenExec.scala:179)\n  at org.apache.spark.sql.execution.ProjectExec.consume(basicPhysicalOperators.scala:35)\n  at org.apache.spark.sql.execution.ProjectExec.doConsume(basicPhysicalOperators.scala:65)\n  at org.apache.spark.sql.execution.CodegenSupport$class.consume(WholeStageCodegenExec.scala:181)\n  at org.apache.spark.sql.execution.FilterExec.consume(basicPhysicalOperators.scala:85)\n  at org.apache.spark.sql.execution.FilterExec.doConsume(basicPhysicalOperators.scala:206)\n  at org.apache.spark.sql.execution.CodegenSupport$class.consume(WholeStageCodegenExec.scala:181)\n  at org.apache.spark.sql.execution.FileSourceScanExec.consume(DataSourceScanExec.scala:158)\n  at org.apache.spark.sql.execution.ColumnarBatchScan$class.produceBatches(ColumnarBatchScan.scala:138)\n  at org.apache.spark.sql.execution.ColumnarBatchScan$class.doProduce(ColumnarBatchScan.scala:78)\n  at org.apache.spark.sql.execution.FileSourceScanExec.doProduce(DataSourceScanExec.scala:158)\n  at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:88)\n  at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:83)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n  at org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:83)\n  at org.apache.spark.sql.execution.FileSourceScanExec.produce(DataSourceScanExec.scala:158)\n  at org.apache.spark.sql.execution.FilterExec.doProduce(basicPhysicalOperators.scala:125)\n  at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:88)\n  at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:83)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n  at org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:83)\n  at org.apache.spark.sql.execution.FilterExec.produce(basicPhysicalOperators.scala:85)\n  at org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)\n  at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:88)\n  at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:83)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n  at org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:83)\n  at org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)\n  at org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:97)\n  at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:88)\n  at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:83)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n  at org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:83)\n  at org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:39)\n  at org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)\n  at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:88)\n  at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:83)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n  at org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:83)\n  at org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)\n  at org.apache.spark.sql.execution.aggregate.HashAggregateExec.doProduceWithoutKeys(HashAggregateExec.scala:234)\n  at org.apache.spark.sql.execution.aggregate.HashAggregateExec.doProduce(HashAggregateExec.scala:163)\n  at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:88)\n  at org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:83)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n  at org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:83)\n  at org.apache.spark.sql.execution.aggregate.HashAggregateExec.produce(HashAggregateExec.scala:39)\n  at org.apache.spark.sql.execution.WholeStageCodegenExec.doCodeGen(WholeStageCodegenExec.scala:524)\n  at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:576)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n  at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:92)\n  at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)\n  at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)\n  at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n  ... 71 more\n"}]},"apps":[],"jobName":"paragraph_1606803624028_-689967844","id":"20201201-062024_1742108802","dateCreated":"2020-12-01T06:20:24+0000","dateStarted":"2020-12-01T06:24:03+0000","dateFinished":"2020-12-01T06:32:14+0000","status":"ABORT","progressUpdateIntervalMs":500,"$$hashKey":"object:14548"},{"title":"Отключение auto broadcast","text":"%md\nОтключить автоматический броадкаст командой spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\"). Сделать джойн с семплом hw2.sample, сравнить время выполнения запроса.\n","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T06:15:48+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Отключить автоматический броадкаст командой spark.conf.set(&ldquo;spark.sql.autoBroadcastJoinThreshold&rdquo;, &ldquo;-1&rdquo;). Сделать джойн с семплом hw2.sample, сравнить время выполнения запроса.</p>\n"}]},"apps":[],"jobName":"paragraph_1606773354948_-624563013","id":"20201128-092252_410955057","dateCreated":"2020-11-30T21:55:54+0000","dateStarted":"2020-12-01T06:15:48+0000","dateFinished":"2020-12-01T06:15:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14549"},{"text":"spark.table(\"hw2.events_full\")\n.join(spark.table(\"hw2.sample\"),Seq(\"event_id\"))\n.count","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T07:01:07+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res2: Long = 74650\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://bigdataanalytics-head-0.novalocal:4040/jobs/job?id=9","http://bigdataanalytics-head-0.novalocal:4040/jobs/job?id=10"],"interpreterSettingId":"spark2"}},"apps":[],"jobName":"paragraph_1606803752746_-99198873","id":"20201201-062232_2014502844","dateCreated":"2020-12-01T06:22:32+0000","dateStarted":"2020-12-01T07:01:07+0000","dateFinished":"2020-12-01T07:02:07+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14550"},{"text":"spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T07:02:16+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1606806093440_-823482914","id":"20201201-070133_1729935298","dateCreated":"2020-12-01T07:01:33+0000","dateStarted":"2020-12-01T07:02:16+0000","dateFinished":"2020-12-01T07:02:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14551"},{"text":"spark.table(\"hw2.events_full\")\n.join(spark.table(\"hw2.sample\"),Seq(\"event_id\"))\n.count","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T07:02:53+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res4: Long = 74650\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://bigdataanalytics-head-0.novalocal:4040/jobs/job?id=11"],"interpreterSettingId":"spark2"}},"apps":[],"jobName":"paragraph_1606806150635_1570895903","id":"20201201-070230_1988723839","dateCreated":"2020-12-01T07:02:30+0000","dateStarted":"2020-12-01T07:02:53+0000","dateFinished":"2020-12-01T07:06:06+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14552"},{"user":"BD_274_mmingalov","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1606806144879_766389208","id":"20201201-070224_1253028013","dateCreated":"2020-12-01T07:02:24+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:14553"},{"title":"Вернуть настройку к исходной","text":"spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"26214400\")","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T07:06:23+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1606773354949_414087330","id":"20201127-230625_1272901030","dateCreated":"2020-11-30T21:55:54+0000","dateStarted":"2020-12-01T07:06:23+0000","dateFinished":"2020-12-01T07:06:24+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14554"},{"text":"spark.sql(\"clear cache\")","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T07:06:29+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res6: org.apache.spark.sql.DataFrame = []\n"}]},"apps":[],"jobName":"paragraph_1606773354949_1855845972","id":"20201128-155645_947820002","dateCreated":"2020-11-30T21:55:54+0000","dateStarted":"2020-12-01T07:06:29+0000","dateFinished":"2020-12-01T07:06:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14555"},{"title":"Задание 4","text":"%md\n.\n.\n.\n\nВ процессе обработки данных может возникнуть перекос объёма партиций по количеству данных (data skew). В таком случае время выполнения запроса может существенно увеличиться, так как данные распределятся по исполнителям неравномерно. В следующем параграфе происходит инициализация датафрейма, этот параграф нужно выполнить, изменять код нельзя. В задании нужно работать с инициализированным датафреймом.\n\nДатафрейм разделен на 30 партиций по ключу city, который имеет сильно  неравномерное распределение.","user":"BD_274_mmingalov","dateUpdated":"2020-11-30T21:55:54+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>.\n<br  />.\n<br  />.</p>\n<p>В процессе обработки данных может возникнуть перекос объёма партиций по количеству данных (data skew). В таком случае время выполнения запроса может существенно увеличиться, так как данные распределятся по исполнителям неравномерно. В следующем параграфе происходит инициализация датафрейма, этот параграф нужно выполнить, изменять код нельзя. В задании нужно работать с инициализированным датафреймом.</p>\n<p>Датафрейм разделен на 30 партиций по ключу city, который имеет сильно  неравномерное распределение.</p>\n"}]},"apps":[],"jobName":"paragraph_1606773354949_1046880878","id":"20201128-163357_1545019956","dateCreated":"2020-11-30T21:55:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:14556"},{"text":"%pyspark \nfrom pyspark.sql.functions import col\n\nskew_df = spark.table(\"hw2.events_full\")\\\n.where(\"date = '2020-11-01'\")\\\n.repartition(30, col(\"city\"))\\\n.cache()\n\nskew_df.count()","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T10:48:43+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"30000000\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://bigdataanalytics-head-0.novalocal:4040/jobs/job?id=40"],"interpreterSettingId":"spark2"}},"apps":[],"jobName":"paragraph_1606773354950_637763572","id":"20201128-162744_575252973","dateCreated":"2020-11-30T21:55:54+0000","dateStarted":"2020-12-01T10:48:43+0000","dateFinished":"2020-12-01T10:51:30+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14558"},{"text":"%md\nskew_df -- датафрэйм из 30 партиций\nи Spark гарантирует, что в каждой партиции лежат строки с одинаковым значением CITY (в отдельной партиции м.б. несколько разных CITY)\n","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T10:52:34+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":false,"tableHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>skew_df &ndash; датафрэйм из 30 партиций\n<br  />и Spark гарантирует, что в каждой партиции лежат строки с одинаковым значением CITY</p>\n"}]},"apps":[],"jobName":"paragraph_1606811810353_-1917056477","id":"20201201-083650_1718879420","dateCreated":"2020-12-01T08:36:50+0000","dateStarted":"2020-12-01T08:38:36+0000","dateFinished":"2020-12-01T08:38:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14559"},{"text":"%sh\nhdfs dfs -ls -h /apps/spark/warehouse/hw2.db/skew_df\n","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T09:58:09+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Found 30 items\n-rw-r--r--   3 zeppelin hdfs          0 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/_SUCCESS\n-rw-r--r--   3 zeppelin hdfs      2.4 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00000-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      4.9 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00001-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      3.7 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00002-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      2.4 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00003-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      6.1 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00004-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      2.5 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00005-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      4.9 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00006-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      2.5 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00007-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      3.6 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00008-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      1.2 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00009-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      6.1 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00010-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      2.4 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00011-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      3.7 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00012-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      6.1 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00013-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      3.7 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00014-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      3.6 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00015-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      4.9 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00016-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      3.7 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00017-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      3.7 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00018-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      8.5 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00019-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      7.3 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00020-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      7.3 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00021-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      4.8 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00022-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      5.5 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00023-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs    618.2 K 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00024-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      4.9 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00025-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      2.4 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00026-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs    549.3 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00027-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      6.1 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00029-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n"}]},"apps":[],"jobName":"paragraph_1606815473788_-1756511220","id":"20201201-093753_290802874","dateCreated":"2020-12-01T09:37:53+0000","dateStarted":"2020-12-01T09:58:09+0000","dateFinished":"2020-12-01T09:58:10+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14560"},{"title":"4.1. Наблюдение проблемы","text":"%md\n.\n.\n.\n\nПосчитать количество event_count различных событий event_id , содержащихся в skew_df с группировкой по городам. Результат упорядочить по event_count.\n\nВ spark ui в разделе jobs выбрать последнюю, в ней зайти в stage, состоящую из 30 тасков (из такого количества партиций состоит skew_df). На странице стейджа нажать кнопку Event Timeline и увидеть время выполнения тасков по экзекьюторам. Одному из них выпала партиция с существенно большим количеством данных. Остальные экзекьюторы в это время бездействуют -- это и является проблемой, которую предлагается решить далее.","user":"BD_274_mmingalov","dateUpdated":"2020-11-30T21:55:54+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>.\n<br  />.\n<br  />.</p>\n<p>Посчитать количество event_count различных событий event_id , содержащихся в skew_df с группировкой по городам. Результат упорядочить по event_count.</p>\n<p>В spark ui в разделе jobs выбрать последнюю, в ней зайти в stage, состоящую из 30 тасков (из такого количества партиций состоит skew_df). На странице стейджа нажать кнопку Event Timeline и увидеть время выполнения тасков по экзекьюторам. Одному из них выпала партиция с существенно большим количеством данных. Остальные экзекьюторы в это время бездействуют &ndash; это и является проблемой, которую предлагается решить далее.</p>\n"}]},"apps":[],"jobName":"paragraph_1606773354950_-1167909820","id":"20201128-164139_1371291032","dateCreated":"2020-11-30T21:55:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:14561"},{"text":"%pyspark\nfrom pyspark.sql.functions import count\n\n(skew_df \\\n.groupBy(\"city\") \\\n.agg(count(\"event_id\").alias(\"event_count\")) \\\n.orderBy(\"event_count\", ascending=False) \\\n.show(1000, False))\n","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T10:53:03+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------+-----------+\n|city          |event_count|\n+--------------+-----------+\n|BIG_CITY      |26998938   |\n|SMALL_CITY_46 |30459      |\n|SMALL_CITY_51 |30405      |\n|SMALL_CITY_3  |30394      |\n|SMALL_CITY_28 |30382      |\n|SMALL_CITY_55 |30345      |\n|SMALL_CITY_45 |30272      |\n|SMALL_CITY_4  |30259      |\n|SMALL_CITY_57 |30244      |\n|SMALL_CITY_83 |30232      |\n|SMALL_CITY_48 |30228      |\n|SMALL_CITY_61 |30226      |\n|SMALL_CITY_33 |30226      |\n|SMALL_CITY_98 |30211      |\n|SMALL_CITY_21 |30207      |\n|SMALL_CITY_30 |30206      |\n|SMALL_CITY_76 |30203      |\n|SMALL_CITY_56 |30198      |\n|SMALL_CITY_91 |30197      |\n|SMALL_CITY_25 |30180      |\n|SMALL_CITY_39 |30178      |\n|SMALL_CITY_67 |30177      |\n|SMALL_CITY_87 |30163      |\n|SMALL_CITY_75 |30161      |\n|SMALL_CITY_66 |30157      |\n|SMALL_CITY_1  |30142      |\n|SMALL_CITY_69 |30139      |\n|SMALL_CITY_20 |30123      |\n|SMALL_CITY_35 |30121      |\n|SMALL_CITY_9  |30118      |\n|SMALL_CITY_7  |30116      |\n|SMALL_CITY_72 |30102      |\n|SMALL_CITY_71 |30099      |\n|SMALL_CITY_49 |30095      |\n|SMALL_CITY_38 |30086      |\n|SMALL_CITY_16 |30082      |\n|SMALL_CITY_32 |30081      |\n|SMALL_CITY_23 |30078      |\n|SMALL_CITY_12 |30078      |\n|SMALL_CITY_89 |30068      |\n|SMALL_CITY_58 |30066      |\n|SMALL_CITY_43 |30058      |\n|SMALL_CITY_24 |30047      |\n|SMALL_CITY_15 |30047      |\n|SMALL_CITY_42 |30041      |\n|SMALL_CITY_74 |30038      |\n|SMALL_CITY_95 |30034      |\n|SMALL_CITY_22 |30020      |\n|SMALL_CITY_85 |30020      |\n|SMALL_CITY_8  |30020      |\n|SMALL_CITY_47 |30009      |\n|SMALL_CITY_86 |29989      |\n|SMALL_CITY_81 |29988      |\n|SMALL_CITY_96 |29983      |\n|SMALL_CITY_41 |29983      |\n|SMALL_CITY_90 |29982      |\n|SMALL_CITY_60 |29981      |\n|SMALL_CITY_2  |29976      |\n|SMALL_CITY_36 |29971      |\n|SMALL_CITY_73 |29955      |\n|SMALL_CITY_18 |29953      |\n|SMALL_CITY_11 |29951      |\n|SMALL_CITY_53 |29951      |\n|SMALL_CITY_14 |29950      |\n|SMALL_CITY_94 |29928      |\n|SMALL_CITY_88 |29927      |\n|SMALL_CITY_54 |29915      |\n|SMALL_CITY_17 |29914      |\n|SMALL_CITY_63 |29911      |\n|SMALL_CITY_34 |29908      |\n|SMALL_CITY_27 |29901      |\n|SMALL_CITY_64 |29898      |\n|SMALL_CITY_79 |29896      |\n|SMALL_CITY_65 |29885      |\n|SMALL_CITY_13 |29878      |\n|SMALL_CITY_5  |29878      |\n|SMALL_CITY_82 |29873      |\n|SMALL_CITY_92 |29873      |\n|SMALL_CITY_26 |29870      |\n|SMALL_CITY_31 |29859      |\n|SMALL_CITY_97 |29851      |\n|SMALL_CITY_62 |29834      |\n|SMALL_CITY_84 |29832      |\n|SMALL_CITY_68 |29832      |\n|SMALL_CITY_29 |29829      |\n|SMALL_CITY_93 |29823      |\n|SMALL_CITY_70 |29823      |\n|SMALL_CITY_99 |29815      |\n|SMALL_CITY_37 |29814      |\n|SMALL_CITY_6  |29808      |\n|SMALL_CITY_80 |29783      |\n|SMALL_CITY_52 |29775      |\n|SMALL_CITY_44 |29773      |\n|SMALL_CITY_59 |29746      |\n|SMALL_CITY_10 |29738      |\n|SMALL_CITY_19 |29730      |\n|SMALL_CITY_50 |29725      |\n|SMALL_CITY_77 |29675      |\n|SMALL_CITY_78 |29605      |\n|SMALL_CITY_40 |29569      |\n|SMALL_CITY_100|15092      |\n|SMALL_CITY_0  |14825      |\n+--------------+-----------+\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://bigdataanalytics-head-0.novalocal:4040/jobs/job?id=41"],"interpreterSettingId":"spark2"}},"apps":[],"jobName":"paragraph_1606806543124_397832021","id":"20201201-070903_2129440070","dateCreated":"2020-12-01T07:09:03+0000","dateStarted":"2020-12-01T10:53:03+0000","dateFinished":"2020-12-01T10:53:10+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14562"},{"title":"4.2. repartition","text":"%md\n.\n.\n.\n\nодин из способов решения проблемы агрегации по неравномерно распределенному ключу является предварительное перемешивание данных. Его можно сделать с помощью метода repartition(p_num), где p_num -- количество партиций, на которые будет перемешан исходный датафрейм","user":"BD_274_mmingalov","dateUpdated":"2020-11-30T21:55:54+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>.\n<br  />.\n<br  />.</p>\n<p>один из способов решения проблемы агрегации по неравномерно распределенному ключу является предварительное перемешивание данных. Его можно сделать с помощью метода repartition(p_num), где p_num &ndash; количество партиций, на которые будет перемешан исходный датафрейм</p>\n"}]},"apps":[],"jobName":"paragraph_1606773354951_-741312229","id":"20201128-164814_1641460265","dateCreated":"2020-11-30T21:55:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:14563"},{"text":"%pyspark\nskew_df \\\n.repartition(10) \\\n.groupBy(\"city\") \\\n.agg(count(\"event_id\").alias(\"event_count\")) \\\n.orderBy(\"event_count\", ascending=False) \\\n.show()\n","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T10:03:49+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------------+-----------+\n|         city|event_count|\n+-------------+-----------+\n|     BIG_CITY|   26998938|\n|SMALL_CITY_46|      30459|\n|SMALL_CITY_51|      30405|\n| SMALL_CITY_3|      30394|\n|SMALL_CITY_28|      30382|\n|SMALL_CITY_55|      30345|\n|SMALL_CITY_45|      30272|\n| SMALL_CITY_4|      30259|\n|SMALL_CITY_57|      30244|\n|SMALL_CITY_83|      30232|\n|SMALL_CITY_48|      30228|\n|SMALL_CITY_61|      30226|\n|SMALL_CITY_33|      30226|\n|SMALL_CITY_98|      30211|\n|SMALL_CITY_21|      30207|\n|SMALL_CITY_30|      30206|\n|SMALL_CITY_76|      30203|\n|SMALL_CITY_56|      30198|\n|SMALL_CITY_91|      30197|\n|SMALL_CITY_25|      30180|\n+-------------+-----------+\nonly showing top 20 rows\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://bigdataanalytics-head-0.novalocal:4040/jobs/job?id=69"],"interpreterSettingId":"spark2"}},"apps":[],"jobName":"paragraph_1606807902446_893731152","id":"20201201-073142_1588971967","dateCreated":"2020-12-01T07:31:42+0000","dateStarted":"2020-12-01T10:03:50+0000","dateFinished":"2020-12-01T10:07:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14564"},{"text":"%sh\nhdfs dfs -ls -h /apps/spark/warehouse/hw2.db/skew_df","user":"BD_274_mmingalov","dateUpdated":"2020-12-01T10:54:24+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/sh","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Found 30 items\n-rw-r--r--   3 zeppelin hdfs          0 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/_SUCCESS\n-rw-r--r--   3 zeppelin hdfs      2.4 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00000-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      4.9 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00001-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      3.7 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00002-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      2.4 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00003-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      6.1 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00004-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      2.5 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00005-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      4.9 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00006-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      2.5 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00007-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      3.6 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00008-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      1.2 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00009-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      6.1 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00010-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      2.4 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00011-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      3.7 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00012-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      6.1 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00013-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      3.7 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00014-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      3.6 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00015-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      4.9 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00016-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      3.7 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00017-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      3.7 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00018-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      8.5 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00019-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      7.3 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00020-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      7.3 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00021-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      4.8 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00022-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      5.5 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00023-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs    618.2 K 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00024-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      4.9 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00025-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      2.4 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00026-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs    549.3 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00027-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n-rw-r--r--   3 zeppelin hdfs      6.1 M 2020-11-30 17:48 /apps/spark/warehouse/hw2.db/skew_df/part-00029-1711e3cd-3b9e-48c4-97e4-3aee9063ecfe-c000.snappy.parquet\n"}]},"apps":[],"jobName":"paragraph_1606816966322_-1390188917","id":"20201201-100246_411879411","dateCreated":"2020-12-01T10:02:46+0000","dateStarted":"2020-12-01T10:07:27+0000","dateFinished":"2020-12-01T10:07:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14565","title":"по-прежнему 30. Но ведь мы не сохраняли df на диск.. верно?"},{"title":"4.3. Key Salting","text":"%md\n.\n.\n.\nДругой способ исправить неравномерность по ключу -- создание синтетического ключа с равномерным распределением. В нашем случае неравномерность исходит от единственного значения city='BIG_CITY', которое часто повторяется в данных и при группировке попадает к одному экзекьютору. В таком случае лучше провести группировку в два этапа по синтетическому ключу CITY_SALT, который принимает значение BIG_CITY_rand (rand -- случайное целое число) для популярного значения BIG_CITY и CITY для остальных значений. На втором этапе восстанавливаем значения CITY и проводим повторную агрегацию, которая не занимает времени, потому что проводится по существенно меньшего размера данным. \n\nТакая же техника применима и к джойнам по неравномерному ключу, см, например https://itnext.io/handling-data-skew-in-apache-spark-9f56343e58e8\n\nЧто нужно реализовать:\n* добавить синтетический ключ\n* группировка по синтетическому ключу\n* восстановление исходного значения\n* группировка по исходной колонке","user":"BD_274_mmingalov","dateUpdated":"2020-11-30T21:55:54+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>.\n<br  />.\n<br  />.\n<br  />Другой способ исправить неравномерность по ключу &ndash; создание синтетического ключа с равномерным распределением. В нашем случае неравномерность исходит от единственного значения city='BIG_CITY', которое часто повторяется в данных и при группировке попадает к одному экзекьютору. В таком случае лучше провести группировку в два этапа по синтетическому ключу CITY_SALT, который принимает значение BIG_CITY_rand (rand &ndash; случайное целое число) для популярного значения BIG_CITY и CITY для остальных значений. На втором этапе восстанавливаем значения CITY и проводим повторную агрегацию, которая не занимает времени, потому что проводится по существенно меньшего размера данным.</p>\n<p>Такая же техника применима и к джойнам по неравномерному ключу, см, например https://itnext.io/handling-data-skew-in-apache-spark-9f56343e58e8</p>\n<p>Что нужно реализовать:</p>\n<ul>\n<li>добавить синтетический ключ</li>\n<li>группировка по синтетическому ключу</li>\n<li>восстановление исходного значения</li>\n<li>группировка по исходной колонке</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1606773354951_-619518602","id":"20201128-173534_1924644474","dateCreated":"2020-11-30T21:55:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:14566"},{"user":"BD_274_mmingalov","dateUpdated":"2020-12-01T11:43:12+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1606773354952_-101892990","id":"20201128-175938_2140404686","dateCreated":"2020-11-30T21:55:54+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14568","focus":true,"text":"%pyspark\nfrom pyspark.sql.functions import monotonically_increasing_id, when, rand, round, expr, lit, sum\n\nsalt_size = 10\n\nskew_df.withColumn(\"salt_index\", round(100 * rand()) )\\\n.withColumn(\"city_salt\", when(col(\"city\") == \"BIG_CITY\", expr(\"CONCAT(city, salt_index)\")).otherwise(col(\"city\")))\\\n.groupBy(\"city_salt\")\\\n.agg(countDistinct(\"event_id\").alias(\"count\"))\\\n.withColumn(\"city\", when(expr(\"city_salt not like 'SMALL%'\"), lit(\"BIG_CITY\")).otherwise(col(\"city_salt\")))\\\n.groupBy(\"city\")\\\n.agg(sum(\"count\").alias(\"count\"))\\\n.orderBy(col(\"count\"), ascending=False)\\\n.show()","dateFinished":"2020-12-01T11:46:47+0000","dateStarted":"2020-12-01T11:43:12+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------------+--------+\n|         city|   count|\n+-------------+--------+\n|     BIG_CITY|26998938|\n|SMALL_CITY_46|   30459|\n|SMALL_CITY_51|   30405|\n| SMALL_CITY_3|   30394|\n|SMALL_CITY_28|   30382|\n|SMALL_CITY_55|   30345|\n|SMALL_CITY_45|   30272|\n| SMALL_CITY_4|   30259|\n|SMALL_CITY_57|   30244|\n|SMALL_CITY_83|   30232|\n|SMALL_CITY_48|   30228|\n|SMALL_CITY_61|   30226|\n|SMALL_CITY_33|   30226|\n|SMALL_CITY_98|   30211|\n|SMALL_CITY_21|   30207|\n|SMALL_CITY_30|   30206|\n|SMALL_CITY_76|   30203|\n|SMALL_CITY_56|   30198|\n|SMALL_CITY_91|   30197|\n|SMALL_CITY_25|   30180|\n+-------------+--------+\nonly showing top 20 rows\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://bigdataanalytics-head-0.novalocal:4040/jobs/job?id=45"],"interpreterSettingId":"spark2"}}},{"text":"spark.stop","user":"BD_274_mmingalov","dateUpdated":"2020-11-30T21:55:54+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1606773354952_-1096640369","id":"20201128-174934_1428813475","dateCreated":"2020-11-30T21:55:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:14567"}],"name":"mmingalov/task_02","id":"2FRPZVCSQ","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"sh:BD_274_mmingalov:":[],"spark2:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}